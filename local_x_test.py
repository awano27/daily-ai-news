#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
XæŠ•ç¨¿å‡¦ç†ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ
"""

import requests
import csv
from io import StringIO
import html
import re
from urllib.parse import urlparse
from datetime import datetime, timezone, timedelta

def test_x_posts_processing():
    """XæŠ•ç¨¿å‡¦ç†ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ§ª XæŠ•ç¨¿å‡¦ç†ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    # è¨­å®š
    X_POSTS_CSV = 'https://docs.google.com/spreadsheets/d/1uuLKCLIJw--a1vCcO6UGxSpBiLTtN8uGl2cdMb6wcfg/export?format=csv&gid=0'
    HOURS_LOOKBACK = 24
    
    try:
        # 1. CSVãƒ‡ãƒ¼ã‚¿å–å¾—
        print("ğŸ“‹ CSVãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")
        response = requests.get(X_POSTS_CSV, timeout=30)
        response.raise_for_status()
        response.encoding = 'utf-8'
        csv_content = response.text.strip()
        
        print(f"âœ… CSVãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {len(csv_content)} æ–‡å­—")
        print(f"ğŸ“„ æœ€åˆã®200æ–‡å­—:")
        print(csv_content[:200])
        print()
        
        # 2. CSVè§£æï¼ˆä¿®æ­£ã•ã‚ŒãŸãƒ­ã‚¸ãƒƒã‚¯ï¼‰
        lines = csv_content.split('\n')
        print(f"ğŸ” CSVè¡Œæ•°: {len(lines)}")
        print("ğŸ” æœ€åˆã®3è¡Œã®è©³ç´°:")
        
        for i, line in enumerate(lines[:3]):
            print(f"  è¡Œ{i+1}: {line}")
        print()
        
        # 3. XæŠ•ç¨¿å‡¦ç†
        x_posts = []
        for i, line in enumerate(lines):
            try:
                # CSVã‚’æ‰‹å‹•ã§è§£æ
                parts = list(csv.reader([line]))[0]
                
                if len(parts) < 3:  # æœ€ä½3åˆ—å¿…è¦
                    continue
                
                # CSVå½¢å¼: [timestamp, username, content, image_url, tweet_url]
                timestamp_str = parts[0].strip()
                username = parts[1].strip().lstrip('@')
                tweet_content = parts[2].strip()
                
                # ãƒ„ã‚¤ãƒ¼ãƒˆURLã¯4åˆ—ç›®ã¾ãŸã¯5åˆ—ç›®
                tweet_url = ''
                if len(parts) > 4:
                    tweet_url = parts[4].strip()
                elif len(parts) > 3:
                    tweet_url = parts[3].strip()
                
                print(f"ğŸ” è¡Œ{i+1} å‡¦ç†ä¸­:")
                print(f"  ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp_str}")
                print(f"  ãƒ¦ãƒ¼ã‚¶ãƒ¼: @{username}")
                print(f"  å†…å®¹: {tweet_content[:100]}...")
                print(f"  URL: {tweet_url}")
                
                if not tweet_content or not username:
                    print("  âŒ ã‚¹ã‚­ãƒƒãƒ—: å†…å®¹ã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼åãŒç©º")
                    continue
                
                # æ—¥ä»˜ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€è¿‘24æ™‚é–“ä»¥å†…ï¼‰
                try:
                    from dateutil import parser
                    post_date = parser.parse(timestamp_str)
                    cutoff_time = datetime.now(timezone.utc) - timedelta(hours=HOURS_LOOKBACK)
                    if post_date.replace(tzinfo=timezone.utc) <= cutoff_time:
                        print(f"  âŒ ã‚¹ã‚­ãƒƒãƒ—: å¤ã„æŠ•ç¨¿ ({timestamp_str})")
                        continue
                except Exception as date_error:
                    print(f"  âš ï¸ æ—¥ä»˜è§£æã‚¨ãƒ©ãƒ¼: {date_error}")
                    continue
                
                # ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                cleaned = re.sub(r"https?://\S+", "", tweet_content)
                cleaned = re.sub(r"\s+", " ", cleaned).strip()
                
                # å¤–éƒ¨URLã‚’æŠ½å‡º
                ext_urls = re.findall(r"https?://\S+", tweet_content)
                ext_url = None
                for url in ext_urls:
                    try:
                        host = urlparse(url).netloc.lower()
                        if not any(x in host for x in ["x.com", "twitter.com", "t.co"]):
                            ext_url = url
                            break
                    except:
                        continue
                
                # ãƒ„ã‚¤ãƒ¼ãƒˆURLè‡ªä½“ã‚’ä½¿ç”¨ï¼ˆä»–ã«é©åˆ‡ãªURLãŒãªã„å ´åˆï¼‰
                if not ext_url and tweet_url:
                    if 'twitter.com' not in tweet_url and 'x.com' not in tweet_url:
                        ext_url = tweet_url
                
                # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
                title = f"ğŸ¦ @{username}: {cleaned[:80]}..." if len(cleaned) > 80 else f"ğŸ¦ @{username}: {cleaned}"
                
                # è¦ç´„ç”Ÿæˆ
                summary = cleaned[:200] + '...' if len(cleaned) > 200 else cleaned
                
                x_posts.append({
                    'title': title,
                    'url': ext_url or tweet_url or '',
                    'summary': summary,
                    'published': timestamp_str,
                    'source': f'X @{username}',
                    'engineer_score': 10.0  # æœ€é«˜ã‚¹ã‚³ã‚¢
                })
                
                print(f"  âœ… å‡¦ç†æˆåŠŸ: ã‚¹ã‚³ã‚¢ 10.0")
                print()
                
                if len(x_posts) >= 5:  # ãƒ†ã‚¹ãƒˆç”¨ã«5ä»¶ã¾ã§
                    break
                    
            except Exception as e:
                print(f"  âŒ è¡Œ{i+1}å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                print()
                continue
        
        print(f"ğŸ“Š XæŠ•ç¨¿å‡¦ç†çµæœ: {len(x_posts)}ä»¶")
        
        # 4. çµæœè¡¨ç¤º
        if x_posts:
            print("\nğŸ¯ å–å¾—ã•ã‚ŒãŸXæŠ•ç¨¿:")
            for i, post in enumerate(x_posts):
                print(f"\næŠ•ç¨¿ {i+1}:")
                print(f"  ã‚¿ã‚¤ãƒˆãƒ«: {post['title']}")
                print(f"  URL: {post['url']}")
                print(f"  è¦ç´„: {post['summary'][:100]}...")
                print(f"  ã‚½ãƒ¼ã‚¹: {post['source']}")
                print(f"  æ—¥æ™‚: {post['published']}")
                print(f"  ã‚¹ã‚³ã‚¢: {post['engineer_score']}")
            
            # 5. ç°¡å˜ãªHTMLãƒ†ã‚¹ãƒˆç”Ÿæˆ
            html_test = generate_test_html(x_posts)
            with open('test_x_posts.html', 'w', encoding='utf-8') as f:
                f.write(html_test)
            
            print(f"\nâœ… ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
            print(f"ğŸ“„ test_x_posts.html ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            print(f"ğŸ¦ {len(x_posts)}ä»¶ã®XæŠ•ç¨¿ã‚’æ­£å¸¸ã«å‡¦ç†")
            return True
        else:
            print("\nâŒ XæŠ•ç¨¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
            
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def generate_test_html(x_posts):
    """ãƒ†ã‚¹ãƒˆç”¨HTMLç”Ÿæˆ"""
    now = datetime.now().strftime('%Y-%m-%d %H:%M')
    
    html_content = f'''<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8"/>
  <title>XæŠ•ç¨¿ãƒ†ã‚¹ãƒˆ - {now}</title>
  <style>
    body {{ font-family: system-ui, sans-serif; margin: 20px; background: #f8fafc; }}
    .container {{ max-width: 800px; margin: 0 auto; }}
    .header {{ text-align: center; margin-bottom: 30px; }}
    .post {{ background: white; border: 1px solid #e2e8f0; border-radius: 8px; padding: 16px; margin-bottom: 16px; }}
    .post-title {{ font-weight: bold; margin-bottom: 8px; color: #1e40af; }}
    .post-meta {{ color: #64748b; font-size: 14px; margin-bottom: 8px; }}
    .post-summary {{ line-height: 1.5; margin-bottom: 8px; }}
    .post-score {{ color: #15803d; font-size: 12px; }}
    a {{ text-decoration: none; color: inherit; }}
    a:hover {{ text-decoration: underline; }}
  </style>
</head>
<body>
  <div class="container">
    <header class="header">
      <h1>ğŸ§ª XæŠ•ç¨¿å‡¦ç†ãƒ†ã‚¹ãƒˆ</h1>
      <p>ç”Ÿæˆæ—¥æ™‚: {now}</p>
      <p>å–å¾—ä»¶æ•°: {len(x_posts)}ä»¶</p>
    </header>
    
    <main>
'''
    
    for i, post in enumerate(x_posts):
        html_content += f'''
      <article class="post">
        <div class="post-title">
          <a href="{post['url']}" target="_blank">{html.escape(post['title'])}</a>
        </div>
        <div class="post-meta">
          {post['source']} Â· {post['published']}
        </div>
        <div class="post-summary">
          {html.escape(post['summary'])}
        </div>
        <div class="post-score">
          æœ‰ç”¨åº¦ã‚¹ã‚³ã‚¢: {post['engineer_score']:.1f}
        </div>
      </article>
'''
    
    html_content += '''
    </main>
  </div>
</body>
</html>
'''
    
    return html_content

if __name__ == "__main__":
    print("ğŸš€ XæŠ•ç¨¿å‡¦ç†ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    success = test_x_posts_processing()
    
    if success:
        print("\nğŸ‰ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        print("ğŸ“ test_x_posts.html ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        print("ğŸ’¡ ã“ã®å‡¦ç†ãŒGitHub Actionsã§ã‚‚æ­£å¸¸ã«å‹•ä½œã™ã‚‹ã¯ãšã§ã™")
    else:
        print("\nğŸ’¥ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        print("ğŸ”§ CSV URLã‚„ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„")